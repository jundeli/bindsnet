{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In /home/junde/miniconda3/envs/kongsr/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/junde/miniconda3/envs/kongsr/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/junde/miniconda3/envs/kongsr/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In /home/junde/miniconda3/envs/kongsr/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/junde/miniconda3/envs/kongsr/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/junde/miniconda3/envs/kongsr/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/junde/miniconda3/envs/kongsr/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/junde/miniconda3/envs/kongsr/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "from time import time as t\n",
    "import sys\n",
    "sys.path.append('../../bindsnet')\n",
    "from network import Network\n",
    "\n",
    "from bindsnet import ROOT_DIR\n",
    "from bindsnet.datasets import MNIST, DataLoader\n",
    "from bindsnet.encoding import PoissonEncoder\n",
    "from bindsnet.evaluation import (\n",
    "    all_activity,\n",
    "    proportion_weighting,\n",
    "    assign_labels,\n",
    ")\n",
    "# from bindsnet.models import DiehlAndCook2015\n",
    "from bindsnet.network.monitors import Monitor\n",
    "from bindsnet.utils import get_square_weights, get_square_assignments\n",
    "from bindsnet.analysis.plotting import (\n",
    "    plot_input,\n",
    "    plot_spikes,\n",
    "    plot_weights,\n",
    "    plot_performance,\n",
    "    plot_assignments,\n",
    "    plot_voltages,\n",
    ")\n",
    "from typing import Optional, Union, Tuple, List, Sequence, Iterable\n",
    "from network.nodes import Input, LIFNodes, DiehlAndCookNodes, AdaptiveLIFNodes\n",
    "from network.topology import Connection, LocalConnection\n",
    "from learning import PostPre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--seed\", type=int, default=0)\n",
    "parser.add_argument(\"--n_neurons\", type=int, default=100)\n",
    "parser.add_argument(\"--batch_size\", type=int, default=32)\n",
    "parser.add_argument(\"--n_epochs\", type=int, default=1)\n",
    "parser.add_argument(\"--n_test\", type=int, default=10000)\n",
    "parser.add_argument(\"--n_train\", type=int, default=1000)\n",
    "parser.add_argument(\"--n_workers\", type=int, default=-1)\n",
    "parser.add_argument(\"--update_steps\", type=int, default=16)\n",
    "parser.add_argument(\"--exc\", type=float, default=22.5)\n",
    "parser.add_argument(\"--inh\", type=float, default=120)\n",
    "parser.add_argument(\"--theta_plus\", type=float, default=0.04)\n",
    "parser.add_argument(\"--time\", type=int, default=100)\n",
    "parser.add_argument(\"--dt\", type=int, default=1.0)\n",
    "parser.add_argument(\"--intensity\", type=float, default=128)\n",
    "parser.add_argument(\"--progress_interval\", type=int, default=10)\n",
    "parser.add_argument(\"--train\", dest=\"train\", action=\"store_true\")\n",
    "parser.add_argument(\"--test\", dest=\"train\", action=\"store_false\")\n",
    "parser.add_argument(\"--plot\", dest=\"plot\", action=\"store_true\")\n",
    "parser.add_argument(\"--gpu\", dest=\"gpu\", action=\"store_true\")\n",
    "parser.set_defaults(plot=True, gpu=False)\n",
    "\n",
    "args = parser.parse_known_args()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on Device =  cpu\n"
     ]
    }
   ],
   "source": [
    "seed = args.seed\n",
    "n_neurons = args.n_neurons\n",
    "batch_size = args.batch_size\n",
    "n_epochs = args.n_epochs\n",
    "n_test = args.n_test\n",
    "n_train = args.n_train\n",
    "n_workers = args.n_workers\n",
    "update_steps = args.update_steps\n",
    "exc = args.exc\n",
    "inh = args.inh\n",
    "theta_plus = args.theta_plus\n",
    "time = args.time\n",
    "dt = args.dt\n",
    "intensity = args.intensity\n",
    "progress_interval = args.progress_interval\n",
    "train = args.train\n",
    "plot = args.plot\n",
    "gpu = args.gpu\n",
    "\n",
    "update_interval = update_steps * batch_size\n",
    "\n",
    "# Sets up Gpu use\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if gpu and torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "else:\n",
    "    torch.manual_seed(seed)\n",
    "    device = \"cpu\"\n",
    "    if gpu:\n",
    "        gpu = False\n",
    "\n",
    "torch.set_num_threads(os.cpu_count() - 1)\n",
    "print(\"Running on Device = \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = 0.25\n",
    "p2 = 0.75\n",
    "class DiehlAndCook2015(Network):\n",
    "    # language=rst\n",
    "    \"\"\"\n",
    "    Implements the spiking neural network architecture from `(Diehl & Cook 2015)\n",
    "    <https://www.frontiersin.org/articles/10.3389/fncom.2015.00099/full>`_.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_inpt: int,\n",
    "        n_neurons: int = 100,\n",
    "        exc: float = 22.5,\n",
    "        inh: float = 17.5,\n",
    "        dt: float = 1.0,\n",
    "        nu: Optional[Union[float, Sequence[float]]] = (1e-4, 1e-2),\n",
    "        reduction: Optional[callable] = None,\n",
    "        wmin: float = 0.0,\n",
    "        wmax: float = 1.0,\n",
    "        norm: float = 78.4,\n",
    "        theta_plus: float = 0.05,\n",
    "        tc_theta_decay: float = 1e7,\n",
    "        inpt_shape: Optional[Iterable[int]] = None,\n",
    "    ) -> None:\n",
    "        # language=rst\n",
    "        \"\"\"\n",
    "        Constructor for class ``DiehlAndCook2015``.\n",
    "\n",
    "        :param n_inpt: Number of input neurons. Matches the 1D size of the input data.\n",
    "        :param n_neurons: Number of excitatory, inhibitory neurons.\n",
    "        :param exc: Strength of synapse weights from excitatory to inhibitory layer.\n",
    "        :param inh: Strength of synapse weights from inhibitory to excitatory layer.\n",
    "        :param dt: Simulation time step.\n",
    "        :param nu: Single or pair of learning rates for pre- and post-synaptic events,\n",
    "            respectively.\n",
    "        :param reduction: Method for reducing parameter updates along the minibatch\n",
    "            dimension.\n",
    "        :param wmin: Minimum allowed weight on input to excitatory synapses.\n",
    "        :param wmax: Maximum allowed weight on input to excitatory synapses.\n",
    "        :param norm: Input to excitatory layer connection weights normalization\n",
    "            constant.\n",
    "        :param theta_plus: On-spike increment of ``DiehlAndCookNodes`` membrane\n",
    "            threshold potential.\n",
    "        :param tc_theta_decay: Time constant of ``DiehlAndCookNodes`` threshold\n",
    "            potential decay.\n",
    "        :param inpt_shape: The dimensionality of the input layer.\n",
    "        \"\"\"\n",
    "        super().__init__(dt=dt)\n",
    "\n",
    "        self.n_inpt = n_inpt\n",
    "        self.inpt_shape = inpt_shape\n",
    "        self.n_neurons = n_neurons\n",
    "        self.exc = exc\n",
    "        self.inh = inh\n",
    "        self.dt = dt\n",
    "\n",
    "        # Layers\n",
    "        input_layer = Input(\n",
    "            n=self.n_inpt, shape=self.inpt_shape, traces=True, tc_trace=20.0\n",
    "        )\n",
    "        exc_layer_1 = DiehlAndCookNodes(\n",
    "            n=int(self.n_neurons*p1),\n",
    "            traces=True,\n",
    "            rest=-65.0,\n",
    "            reset=-60.0,\n",
    "            thresh=-56.16,\n",
    "            refrac=5,\n",
    "            tc_decay=100.0,\n",
    "            tc_trace=20.0,\n",
    "            theta_plus=theta_plus,\n",
    "            tc_theta_decay=tc_theta_decay,\n",
    "        )\n",
    "        \n",
    "        exc_layer_2 = DiehlAndCookNodes(\n",
    "            n=int(self.n_neurons*p2),\n",
    "            traces=True,\n",
    "            rest=-65.0,\n",
    "            reset=-60.0,\n",
    "            thresh=-56.16,\n",
    "            refrac=5,\n",
    "            tc_decay=100.0,\n",
    "            tc_trace=20.0,\n",
    "            theta_plus=theta_plus,\n",
    "            tc_theta_decay=tc_theta_decay,\n",
    "        )\n",
    "        \n",
    "        inh_layer = LIFNodes(\n",
    "            n=self.n_neurons,\n",
    "            traces=False,\n",
    "            rest=-60.0,\n",
    "            reset=-45.0,\n",
    "            thresh=-36,\n",
    "            tc_decay=10.0,\n",
    "            refrac=2,\n",
    "            tc_trace=20.0,\n",
    "        )\n",
    "\n",
    "        # Connections\n",
    "        w = 0.3 * torch.rand(self.n_inpt, self.n_neurons)\n",
    "        input_exc_conn_1 = Connection(\n",
    "            source=input_layer,\n",
    "            target=exc_layer_1,\n",
    "            w=w[:, :int(self.n_neurons*p1)],\n",
    "            update_rule=PostPre,\n",
    "            nu=nu,\n",
    "            reduction=reduction,\n",
    "            wmin=wmin,\n",
    "            wmax=wmax,\n",
    "            norm=norm,\n",
    "        )\n",
    "        input_exc_conn_2 = Connection(\n",
    "            source=input_layer,\n",
    "            target=exc_layer_2,\n",
    "            w=w[:, int(self.n_neurons*p1):],\n",
    "            update_rule=PostPre,\n",
    "            nu=nu,\n",
    "            reduction=reduction,\n",
    "            wmin=wmin,\n",
    "            wmax=wmax,\n",
    "            norm=norm,\n",
    "        )\n",
    "        \n",
    "        w = self.exc * torch.diag(torch.ones(self.n_neurons))\n",
    "        exc_inh_conn_1 = Connection(\n",
    "            source=exc_layer_1, target=inh_layer, w=w[:int(self.n_neurons*p1), :], wmin=0, wmax=self.exc\n",
    "        )\n",
    "        exc_inh_conn_2 = Connection(\n",
    "            source=exc_layer_2, target=inh_layer, w=w[int(self.n_neurons*p1):, :], wmin=0, wmax=self.exc\n",
    "        )\n",
    "        \n",
    "        w = -self.inh * (\n",
    "            torch.ones(self.n_neurons, self.n_neurons)\n",
    "            - torch.diag(torch.ones(self.n_neurons))\n",
    "        )\n",
    "        inh_exc_conn_1 = Connection(\n",
    "            source=inh_layer, target=exc_layer_1, w=w[:, :int(self.n_neurons*p1)], wmin=-self.inh, wmax=0\n",
    "        )\n",
    "        inh_exc_conn_2 = Connection(\n",
    "            source=inh_layer, target=exc_layer_2, w=w[:, int(self.n_neurons*p1):], wmin=-self.inh, wmax=0\n",
    "        )\n",
    "\n",
    "\n",
    "        # Add to network\n",
    "        self.add_layer(input_layer, name=\"X\")\n",
    "        self.add_layer(exc_layer_1, name=\"Ae1\")\n",
    "        self.add_layer(exc_layer_2, name=\"Ae2\")\n",
    "        self.add_layer(inh_layer, name=\"Ai\")\n",
    "        self.add_connection(input_exc_conn_1, source=\"X\", target=\"Ae1\")\n",
    "        self.add_connection(input_exc_conn_2, source=\"X\", target=\"Ae2\")\n",
    "        \n",
    "        self.add_connection(exc_inh_conn_1, source=\"Ae1\", target=\"Ai\")\n",
    "        self.add_connection(exc_inh_conn_2, source=\"Ae2\", target=\"Ai\")\n",
    "        self.add_connection(inh_exc_conn_1, source=\"Ai\", target=\"Ae1\")\n",
    "        self.add_connection(inh_exc_conn_2, source=\"Ai\", target=\"Ae2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determines number of workers to use\n",
    "if n_workers == -1:\n",
    "    n_workers = gpu * 4 * torch.cuda.device_count()\n",
    "\n",
    "n_sqrt = int(np.ceil(np.sqrt(n_neurons)))\n",
    "start_intensity = intensity\n",
    "\n",
    "# Build network.\n",
    "network = DiehlAndCook2015(\n",
    "    n_inpt=784,\n",
    "    n_neurons=n_neurons,\n",
    "    exc=exc,\n",
    "    inh=inh,\n",
    "    dt=dt,\n",
    "    norm=78.4,\n",
    "    nu=(1e-4, 1e-2),\n",
    "    theta_plus=theta_plus,\n",
    "    inpt_shape=(1, 28, 28),\n",
    ")\n",
    "\n",
    "# Directs network to GPU\n",
    "if gpu:\n",
    "    network.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load MNIST data.\n",
    "dataset = MNIST(\n",
    "    PoissonEncoder(time=time, dt=dt),\n",
    "    None,\n",
    "    root=os.path.join(ROOT_DIR, \"data\", \"MNIST\"),\n",
    "    download=True,\n",
    "    transform=transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Lambda(lambda x: x * intensity)]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neuron assignments and spike proportions.\n",
    "n_classes = 10\n",
    "assignments = -torch.ones(n_neurons, device=device)\n",
    "proportions = torch.zeros((n_neurons, n_classes), device=device)\n",
    "rates = torch.zeros((n_neurons, n_classes), device=device)\n",
    "\n",
    "# Sequence of accuracy estimates.\n",
    "accuracy = {\"all\": [], \"proportion\": []}\n",
    "\n",
    "# Voltage recording for excitatory and inhibitory layers.\n",
    "exc_voltage_monitor_1 = Monitor(network.layers[\"Ae1\"], [\"v\"], time=int(time / dt))\n",
    "exc_voltage_monitor_2 = Monitor(network.layers[\"Ae2\"], [\"v\"], time=int(time / dt))\n",
    "inh_voltage_monitor = Monitor(network.layers[\"Ai\"], [\"v\"], time=int(time / dt))\n",
    "network.add_monitor(exc_voltage_monitor_1, name=\"exc_voltage_1\")\n",
    "network.add_monitor(exc_voltage_monitor_2, name=\"exc_voltage_2\")\n",
    "network.add_monitor(inh_voltage_monitor, name=\"inh_voltage\")\n",
    "\n",
    "# Set up monitors for spikes and voltages\n",
    "spikes = {}\n",
    "for layer in set(network.layers):\n",
    "    spikes[layer] = Monitor(\n",
    "        network.layers[layer], state_vars=[\"s\"], time=int(time / dt)\n",
    "    )\n",
    "    network.add_monitor(spikes[layer], name=\"%s_spikes\" % layer)\n",
    "\n",
    "voltages = {}\n",
    "for layer in set(network.layers) - {\"X\"}:\n",
    "    voltages[layer] = Monitor(\n",
    "        network.layers[layer], state_vars=[\"v\"], time=int(time / dt)\n",
    "    )\n",
    "    network.add_monitor(voltages[layer], name=\"%s_voltages\" % layer)\n",
    "\n",
    "inpt_ims, inpt_axes = None, None\n",
    "spike_ims, spike_axes = None, None\n",
    "weights_im = None\n",
    "assigns_im = None\n",
    "perf_ax = None\n",
    "voltage_axes, voltage_ims = None, None\n",
    "\n",
    "spike_record = torch.zeros((update_interval, int(time / dt), n_neurons), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Begin training.\n",
      "\n",
      "\n",
      " Progress: 0 / 1 (0.0015 seconds)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 16/1000 [00:10<09:49,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 8.59 (last), 8.59 (average), 8.59 (best)\n",
      "Proportion weighting accuracy: 8.59 (last), 8.59 (average), 8.59 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 32/1000 [00:19<10:02,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 18.55 (last), 13.57 (average), 18.55 (best)\n",
      "Proportion weighting accuracy: 18.95 (last), 13.77 (average), 18.95 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 48/1000 [00:30<11:14,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 20.12 (last), 15.76 (average), 20.12 (best)\n",
      "Proportion weighting accuracy: 20.51 (last), 16.02 (average), 20.51 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 64/1000 [00:40<09:03,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 22.27 (last), 17.38 (average), 22.27 (best)\n",
      "Proportion weighting accuracy: 22.46 (last), 17.63 (average), 22.46 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 80/1000 [00:49<08:51,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 19.73 (last), 17.85 (average), 22.27 (best)\n",
      "Proportion weighting accuracy: 20.90 (last), 18.28 (average), 22.46 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 96/1000 [00:59<09:19,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 23.05 (last), 18.72 (average), 23.05 (best)\n",
      "Proportion weighting accuracy: 23.44 (last), 19.14 (average), 23.44 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 112/1000 [01:10<09:40,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 17.77 (last), 18.58 (average), 23.05 (best)\n",
      "Proportion weighting accuracy: 18.75 (last), 19.08 (average), 23.44 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 128/1000 [01:19<08:11,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 19.53 (last), 18.70 (average), 23.05 (best)\n",
      "Proportion weighting accuracy: 20.90 (last), 19.31 (average), 23.44 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 144/1000 [01:28<07:58,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 18.55 (last), 18.68 (average), 23.05 (best)\n",
      "Proportion weighting accuracy: 19.92 (last), 19.38 (average), 23.44 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 160/1000 [01:37<07:58,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 17.77 (last), 18.59 (average), 23.05 (best)\n",
      "Proportion weighting accuracy: 20.12 (last), 19.45 (average), 23.44 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 176/1000 [01:48<08:16,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 17.58 (last), 18.50 (average), 23.05 (best)\n",
      "Proportion weighting accuracy: 18.55 (last), 19.37 (average), 23.44 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 192/1000 [01:57<07:40,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 17.58 (last), 18.42 (average), 23.05 (best)\n",
      "Proportion weighting accuracy: 22.27 (last), 19.61 (average), 23.44 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 208/1000 [02:06<07:17,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 13.28 (last), 18.03 (average), 23.05 (best)\n",
      "Proportion weighting accuracy: 16.41 (last), 19.37 (average), 23.44 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 224/1000 [02:15<07:11,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 10.16 (last), 17.47 (average), 23.05 (best)\n",
      "Proportion weighting accuracy: 13.09 (last), 18.92 (average), 23.44 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 240/1000 [02:24<07:07,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 15.23 (last), 17.32 (average), 23.05 (best)\n",
      "Proportion weighting accuracy: 17.77 (last), 18.84 (average), 23.44 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 256/1000 [02:33<08:35,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 13.67 (last), 17.09 (average), 23.05 (best)\n",
      "Proportion weighting accuracy: 14.65 (last), 18.58 (average), 23.44 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 272/1000 [02:44<07:19,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 15.04 (last), 16.97 (average), 23.05 (best)\n",
      "Proportion weighting accuracy: 16.02 (last), 18.43 (average), 23.44 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 288/1000 [02:53<07:29,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 11.91 (last), 16.69 (average), 23.05 (best)\n",
      "Proportion weighting accuracy: 11.72 (last), 18.06 (average), 23.44 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 304/1000 [03:03<06:20,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 10.94 (last), 16.39 (average), 23.05 (best)\n",
      "Proportion weighting accuracy: 11.91 (last), 17.73 (average), 23.44 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 320/1000 [03:12<06:12,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 11.72 (last), 16.15 (average), 23.05 (best)\n",
      "Proportion weighting accuracy: 11.72 (last), 17.43 (average), 23.44 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 336/1000 [03:21<06:01,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 10.16 (last), 15.87 (average), 23.05 (best)\n",
      "Proportion weighting accuracy: 11.72 (last), 17.16 (average), 23.44 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 352/1000 [03:30<05:57,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 10.55 (last), 15.62 (average), 23.05 (best)\n",
      "Proportion weighting accuracy: 11.33 (last), 16.89 (average), 23.44 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 368/1000 [03:39<06:03,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 13.28 (last), 15.52 (average), 23.05 (best)\n",
      "Proportion weighting accuracy: 13.48 (last), 16.75 (average), 23.44 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 384/1000 [03:49<05:46,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 12.11 (last), 15.38 (average), 23.05 (best)\n",
      "Proportion weighting accuracy: 11.72 (last), 16.54 (average), 23.44 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 400/1000 [03:57<05:24,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 10.35 (last), 15.18 (average), 23.05 (best)\n",
      "Proportion weighting accuracy: 10.55 (last), 16.30 (average), 23.44 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 416/1000 [04:06<05:30,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 8.98 (last), 14.94 (average), 23.05 (best)\n",
      "Proportion weighting accuracy: 10.55 (last), 16.08 (average), 23.44 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 432/1000 [04:16<05:56,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 11.91 (last), 14.83 (average), 23.05 (best)\n",
      "Proportion weighting accuracy: 13.09 (last), 15.96 (average), 23.44 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 448/1000 [04:24<05:16,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 10.35 (last), 14.67 (average), 23.05 (best)\n",
      "Proportion weighting accuracy: 11.91 (last), 15.82 (average), 23.44 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 464/1000 [04:33<04:59,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 9.96 (last), 14.51 (average), 23.05 (best)\n",
      "Proportion weighting accuracy: 11.91 (last), 15.69 (average), 23.44 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 480/1000 [04:42<05:02,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 8.59 (last), 14.31 (average), 23.05 (best)\n",
      "Proportion weighting accuracy: 9.57 (last), 15.48 (average), 23.44 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 496/1000 [04:52<05:32,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 8.59 (last), 14.13 (average), 23.05 (best)\n",
      "Proportion weighting accuracy: 10.55 (last), 15.32 (average), 23.44 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 512/1000 [05:01<04:27,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 8.79 (last), 13.96 (average), 23.05 (best)\n",
      "Proportion weighting accuracy: 10.55 (last), 15.17 (average), 23.44 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 528/1000 [05:10<04:20,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 8.59 (last), 13.80 (average), 23.05 (best)\n",
      "Proportion weighting accuracy: 9.57 (last), 15.00 (average), 23.44 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 544/1000 [05:19<04:11,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 8.20 (last), 13.63 (average), 23.05 (best)\n",
      "Proportion weighting accuracy: 8.79 (last), 14.82 (average), 23.44 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 560/1000 [05:28<03:59,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 7.03 (last), 13.44 (average), 23.05 (best)\n",
      "Proportion weighting accuracy: 8.98 (last), 14.65 (average), 23.44 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 576/1000 [05:36<03:50,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 8.98 (last), 13.32 (average), 23.05 (best)\n",
      "Proportion weighting accuracy: 9.77 (last), 14.52 (average), 23.44 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 592/1000 [05:45<03:44,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 9.38 (last), 13.21 (average), 23.05 (best)\n",
      "Proportion weighting accuracy: 10.55 (last), 14.41 (average), 23.44 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 608/1000 [05:54<03:45,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 7.81 (last), 13.07 (average), 23.05 (best)\n",
      "Proportion weighting accuracy: 8.20 (last), 14.25 (average), 23.44 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 624/1000 [06:03<03:22,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 8.98 (last), 12.97 (average), 23.05 (best)\n",
      "Proportion weighting accuracy: 9.38 (last), 14.12 (average), 23.44 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 640/1000 [06:12<03:11,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 8.40 (last), 12.85 (average), 23.05 (best)\n",
      "Proportion weighting accuracy: 8.98 (last), 13.99 (average), 23.44 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 656/1000 [06:21<03:11,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 10.16 (last), 12.79 (average), 23.05 (best)\n",
      "Proportion weighting accuracy: 10.55 (last), 13.91 (average), 23.44 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 672/1000 [06:30<03:02,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 8.59 (last), 12.69 (average), 23.05 (best)\n",
      "Proportion weighting accuracy: 9.57 (last), 13.81 (average), 23.44 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 688/1000 [06:39<02:47,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 8.01 (last), 12.58 (average), 23.05 (best)\n",
      "Proportion weighting accuracy: 8.79 (last), 13.69 (average), 23.44 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 704/1000 [06:48<02:41,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 8.79 (last), 12.49 (average), 23.05 (best)\n",
      "Proportion weighting accuracy: 9.38 (last), 13.59 (average), 23.44 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 720/1000 [06:57<02:34,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 10.16 (last), 12.44 (average), 23.05 (best)\n",
      "Proportion weighting accuracy: 11.91 (last), 13.55 (average), 23.44 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 736/1000 [07:06<02:29,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 8.59 (last), 12.36 (average), 23.05 (best)\n",
      "Proportion weighting accuracy: 9.57 (last), 13.47 (average), 23.44 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 752/1000 [07:16<02:49,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 6.84 (last), 12.24 (average), 23.05 (best)\n",
      "Proportion weighting accuracy: 7.03 (last), 13.33 (average), 23.44 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 768/1000 [07:27<02:20,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 7.81 (last), 12.15 (average), 23.05 (best)\n",
      "Proportion weighting accuracy: 8.01 (last), 13.22 (average), 23.44 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 784/1000 [07:36<01:57,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 8.79 (last), 12.08 (average), 23.05 (best)\n",
      "Proportion weighting accuracy: 9.96 (last), 13.15 (average), 23.44 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 800/1000 [07:45<01:57,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 7.42 (last), 11.98 (average), 23.05 (best)\n",
      "Proportion weighting accuracy: 8.01 (last), 13.05 (average), 23.44 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 816/1000 [07:55<01:53,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 10.35 (last), 11.95 (average), 23.05 (best)\n",
      "Proportion weighting accuracy: 11.52 (last), 13.02 (average), 23.44 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 832/1000 [08:09<02:10,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 9.57 (last), 11.91 (average), 23.05 (best)\n",
      "Proportion weighting accuracy: 10.94 (last), 12.98 (average), 23.44 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 848/1000 [08:20<01:33,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 7.62 (last), 11.83 (average), 23.05 (best)\n",
      "Proportion weighting accuracy: 7.81 (last), 12.88 (average), 23.44 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 864/1000 [08:29<01:16,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 8.40 (last), 11.76 (average), 23.05 (best)\n",
      "Proportion weighting accuracy: 9.18 (last), 12.81 (average), 23.44 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 880/1000 [08:39<01:21,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 7.62 (last), 11.69 (average), 23.05 (best)\n",
      "Proportion weighting accuracy: 8.20 (last), 12.73 (average), 23.44 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 896/1000 [08:51<01:00,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 7.81 (last), 11.62 (average), 23.05 (best)\n",
      "Proportion weighting accuracy: 8.79 (last), 12.66 (average), 23.44 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 912/1000 [09:00<00:51,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 8.20 (last), 11.56 (average), 23.05 (best)\n",
      "Proportion weighting accuracy: 8.98 (last), 12.60 (average), 23.44 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 928/1000 [09:10<00:41,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 11.33 (last), 11.55 (average), 23.05 (best)\n",
      "Proportion weighting accuracy: 11.72 (last), 12.58 (average), 23.44 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 944/1000 [09:19<00:31,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 9.57 (last), 11.52 (average), 23.05 (best)\n",
      "Proportion weighting accuracy: 9.96 (last), 12.54 (average), 23.44 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 960/1000 [09:28<00:21,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 10.94 (last), 11.51 (average), 23.05 (best)\n",
      "Proportion weighting accuracy: 11.13 (last), 12.51 (average), 23.44 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 976/1000 [09:36<00:12,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 7.81 (last), 11.45 (average), 23.05 (best)\n",
      "Proportion weighting accuracy: 8.40 (last), 12.45 (average), 23.44 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 992/1000 [09:45<00:04,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 10.55 (last), 11.44 (average), 23.05 (best)\n",
      "Proportion weighting accuracy: 11.13 (last), 12.42 (average), 23.44 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [09:50,  1.82it/s]                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 1 / 1 (590.9728 seconds)\n",
      "Training complete.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the network.\n",
    "print(\"\\nBegin training.\\n\")\n",
    "start = t()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    labels = []\n",
    "\n",
    "    if epoch % progress_interval == 0:\n",
    "        print(\"\\n Progress: %d / %d (%.4f seconds)\" % (epoch, n_epochs, t() - start))\n",
    "        start = t()\n",
    "\n",
    "    # Create a dataloader to iterate and batch data\n",
    "    train_dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=n_workers,\n",
    "        pin_memory=gpu,\n",
    "    )\n",
    "\n",
    "    pbar_training = tqdm(total=n_train)\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        if step > n_train:\n",
    "            break\n",
    "        # Get next input sample.\n",
    "        inputs = {\"X\": batch[\"encoded_image\"]}\n",
    "        if gpu:\n",
    "            inputs = {k: v.cuda() for k, v in inputs.items()}\n",
    "\n",
    "        if step % update_steps == 0 and step > 0:\n",
    "            # Convert the array of labels into a tensor\n",
    "            label_tensor = torch.tensor(labels, device=device)\n",
    "\n",
    "            # Get network predictions.\n",
    "            all_activity_pred = all_activity(\n",
    "                spikes=spike_record,\n",
    "                assignments=assignments,\n",
    "                n_labels=n_classes,\n",
    "            )\n",
    "            proportion_pred = proportion_weighting(\n",
    "                spikes=spike_record,\n",
    "                assignments=assignments,\n",
    "                proportions=proportions,\n",
    "                n_labels=n_classes,\n",
    "            )\n",
    "\n",
    "            # Compute network accuracy according to available classification strategies.\n",
    "            accuracy[\"all\"].append(\n",
    "                100\n",
    "                * torch.sum(label_tensor.long() == all_activity_pred).item()\n",
    "                / len(label_tensor)\n",
    "            )\n",
    "            accuracy[\"proportion\"].append(\n",
    "                100\n",
    "                * torch.sum(label_tensor.long() == proportion_pred).item()\n",
    "                / len(label_tensor)\n",
    "            )\n",
    "\n",
    "            print(\n",
    "                \"\\nAll activity accuracy: %.2f (last), %.2f (average), %.2f (best)\"\n",
    "                % (\n",
    "                    accuracy[\"all\"][-1],\n",
    "                    np.mean(accuracy[\"all\"]),\n",
    "                    np.max(accuracy[\"all\"]),\n",
    "                )\n",
    "            )\n",
    "            print(\n",
    "                \"Proportion weighting accuracy: %.2f (last), %.2f (average), %.2f\"\n",
    "                \" (best)\\n\"\n",
    "                % (\n",
    "                    accuracy[\"proportion\"][-1],\n",
    "                    np.mean(accuracy[\"proportion\"]),\n",
    "                    np.max(accuracy[\"proportion\"]),\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # Assign labels to excitatory layer neurons.\n",
    "            assignments, proportions, rates = assign_labels(\n",
    "                spikes=spike_record,\n",
    "                labels=label_tensor,\n",
    "                n_labels=n_classes,\n",
    "                rates=rates,\n",
    "            )\n",
    "\n",
    "            labels = []\n",
    "\n",
    "        labels.extend(batch[\"label\"].tolist())\n",
    "\n",
    "        # Run the network on the input.\n",
    "        network.run(inputs=inputs, time=time, input_time_dim=1)\n",
    "\n",
    "        # Add to spikes recording.\n",
    "        s = torch.cat((spikes[\"Ae1\"].get(\"s\").permute((1, 0, 2)), spikes[\"Ae2\"].get(\"s\").permute((1, 0, 2))), -1)\n",
    "#         print('~~~~~~', s.shape)\n",
    "        spike_record[\n",
    "            (step * batch_size)\n",
    "            % update_interval : (step * batch_size % update_interval)\n",
    "            + s.size(0)\n",
    "        ] = s\n",
    "\n",
    "        # Get voltage recording.\n",
    "        exc_voltages_1 = exc_voltage_monitor_1.get(\"v\")\n",
    "        exc_voltages_2 = exc_voltage_monitor_2.get(\"v\")\n",
    "        inh_voltages = inh_voltage_monitor.get(\"v\")\n",
    "\n",
    "\n",
    "        network.reset_state_variables()  # Reset state variables.\n",
    "        pbar_training.update()\n",
    "\n",
    "print(\"Progress: %d / %d (%.4f seconds)\" % (epoch + 1, n_epochs, t() - start))\n",
    "print(\"Training complete.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kongsr",
   "language": "python",
   "name": "kongsr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
